{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl articles\n",
    "http://www-03.ibm.com/press/us/en/pressreleases/recent.wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www-03.ibm.com/press/us/en/pressreleases/recent.wss'\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "#print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles = []\n",
    "for href in soup.findAll(href=re.compile('[0-9]+\\.wss')):\n",
    "    articles.append(href.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/press/us/en/pressrelease/49018.wss'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    article_url = 'http://www-03.ibm.com%s' % article\n",
    "    html = urllib.urlopen(article_url).read()\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    text = soup.find('div',class_='ibm-container-body').text\n",
    "    text = text.replace('\\t','')\n",
    "    text = text.replace('\\n','')\n",
    "    name  = re.findall('[0-9]+',article)[0]\n",
    "    f = open('Articles/%s.txt' % name,'w')\n",
    "    f.write(text.encode('utf-8'))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for txt in glob.glob('Articles/*.txt'):\n",
    "    text+=json.dumps(open(txt,'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "text = nltk.Text(tokens)\n",
    "content = [w for w in text if w.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 624), ('the', 457), ('to', 391), ('of', 302), ('IBM', 234), ('a', 211), ('in', 209), ('for', 141), ('with', 114), ('is', 107), ('on', 97), ('will', 82), ('that', 81), ('more', 80), ('as', 77), ('data', 74), ('new', 71), ('The', 69), ('Watson', 67), ('their', 62)]\n"
     ]
    }
   ],
   "source": [
    "bag_of_words_simple = FreqDist(content)\n",
    "rank = sorted(bag_of_words_simple.items(),key= lambda s:s[1],reverse=True)\n",
    "print rank[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag-of-words with stemming and stop word removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'IBM', 234), (u'data', 74), (u'new', 71), (u'Watson', 67), (u'servic', 66), (u'cloud', 63), (u'busi', 55), (u'provid', 54), (u'develop', 49), (u'help', 48), (u'health', 48), (u'Cloud', 46), (u'platform', 44), (u'custom', 42), (u'digit', 41), (u'technolog', 41), (u'market', 39), (u'inform', 39), (u'solut', 39), (u'offer', 38)]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "porter = nltk.PorterStemmer()\n",
    "content_nostop_stem = [porter.stem(w) for w in text if w.lower() not in stopwords if w.isalpha()]\n",
    "bag_of_words_nostop_stem = FreqDist(content_nostop_stem)\n",
    "rank = sorted(bag_of_words_nostop_stem.items(),key= lambda s:s[1],reverse=True)\n",
    "print rank[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# POS (Part of Speech) and NNP approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('IBM', 'NNP'), 234), (('Watson', 'NNP'), 67), (('data', 'NNS'), 67), (('services', 'NNS'), 55), (('cloud', 'NN'), 53), (('health', 'NN'), 48), (('Cloud', 'NNP'), 46), (('business', 'NN'), 39), (('information', 'NN'), 37), (('platform', 'NN'), 36), (('technology', 'NN'), 30), (('clients', 'NNS'), 29), (('analytics', 'NNS'), 27), (('insights', 'NNS'), 27), (('visit', 'NN'), 26), (('customers', 'NNS'), 24), (('today', 'NN'), 23), (('company', 'NN'), 23), (('NYSE', 'NNP'), 21), (('solution', 'NN'), 21)]\n"
     ]
    }
   ],
   "source": [
    "POS = nltk.pos_tag(tokens)\n",
    "tags = [(word,tag) for (word,tag) in POS if tag.startswith('N') if word.isalpha()]\n",
    "tag_fd = FreqDist(tags)\n",
    "rank = sorted(tag_fd.items(),key= lambda s:s[1],reverse=True)\n",
    "print rank[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
